{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557c66b-70f9-48b8-a2df-63c5604e62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget\n",
    "%pdb off\n",
    "\n",
    "from pyCascade import probePost, physics, utils\n",
    "from pyCascade.probeReadWrite import read_probes_file_switch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "from IPython.core.debugger import set_trace\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fnmatch import fnmatch\n",
    "from cycler import cycler\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import re\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "im_scaling = .75\n",
    "plt.rcParams['figure.figsize'] = [6.4 * im_scaling, 4.8 * im_scaling]\n",
    "\n",
    "category =  \"config2\"\n",
    "\n",
    "############ Universal ################\n",
    "scratch_home = os.getenv('SCRATCH') #need to set SCRATCH (even if there is no real SCRATCH) to the location where results are written\n",
    "scratch_dir = f'{scratch_home}/Cascade/city_block_cfd'\n",
    "home_dir = !pwd\n",
    "home_dir = home_dir[0]\n",
    "\n",
    "display(scratch_dir)\n",
    "display(home_dir)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abdaf328",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 68\n",
    "probes_dir = f'{scratch_dir}/CHARLES/{category}/R{run}/probes/probesOut'\n",
    "oak_probes_dir =  f'{home_dir}/CHARLES/{category}/R{run}/probes/probesOut_parquet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c51c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "qoisOutputed = [\"comp(u,0)\", \"comp(u,1)\", \"comp(u,2)\", \"p\", \"T\", \"D\", \"S\"]\n",
    "probesV = probePost.Probes(probes_dir, directory_parquet = oak_probes_dir, probe_type = \"VOLUMETRIC_PROBES\", flux_quants = qoisOutputed, file_type = \"csv\", name_pattern=\"room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1c8cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 120000# 30000\n",
    "stop = 160000 - 1\n",
    "by = 1\n",
    "\n",
    "steps = pd.Series(probesV.probe_steps, index=probesV.probe_times.index)\n",
    "steps = steps.loc[start:stop:by].values\n",
    "times = probesV.probe_times.loc[steps]\n",
    "names = [name for name in  probesV.probe_names if \"_h_0--1\" in name]\n",
    "qois = ['D', 'T', 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = probesV.statistics(\n",
    "    names = names, \n",
    "    steps = steps,\n",
    "    quants = qois,\n",
    "    parrallel=True,\n",
    "    # processing = [exponential_fit]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85c94a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fitting function for taus\n",
    "def exponential_fit(y, time = times, c = None):\n",
    "    # Convert input to numpy arrays if they are pandas Series\n",
    "    time = time.copy()\n",
    "    y = y.copy()\n",
    "    if hasattr(y, 'values'):\n",
    "        y = y.values\n",
    "    if hasattr(time, 'values'):\n",
    "        time = time.values\n",
    "    if y[0] == 0:\n",
    "        return [0, 0]\n",
    "    time -= time[0]\n",
    "    y += 1e-6\n",
    "    y /= y[0]\n",
    "    if c == None:\n",
    "        exp_decay = lambda x, a, c: (1 - c) * np.exp(-x/a) + c #define theoretical exponential decay function\n",
    "        popt, _ = sp.optimize.curve_fit(exp_decay, time, y, p0=[100, 0], bounds=([0, 0], [np.inf, 1]))\n",
    "    else:\n",
    "        exp_decay = lambda x, a: (1 - c) * np.exp(-x/a) + c #define theoretical exponential decay function\n",
    "        popt, _ = sp.optimize.curve_fit(exp_decay, time, y, p0=100, bounds=(0, np.inf))\n",
    "        popt = np.append(popt, c)\n",
    "    return popt\n",
    "\n",
    "taus = pd.DataFrame()\n",
    "taus['D'] = df['D'].map(lambda y: exponential_fit(y, c = 0))\n",
    "taus['T'] = df['T'].map(exponential_fit)\n",
    "# taus['S'] = df['S'].map(exponential_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a7252c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the fitting function\n",
    "# def exponential_fit(y, time = times):\n",
    "#     # Convert input to numpy arrays if they are pandas Series\n",
    "#     if hasattr(y, 'values'):\n",
    "#         y = y.values\n",
    "#     if hasattr(time, 'values'):\n",
    "#         time = time.values\n",
    "\n",
    "#     time -= time[0]\n",
    "    \n",
    "#     # Avoid log(0) by adding a small constant\n",
    "#     log_y = np.log(y + 1e-6)\n",
    "    \n",
    "#     # Fit a line through the origin using least squares\n",
    "#     slope, residuals, rank, singular_values = np.linalg.lstsq(time[:, np.newaxis], log_y, rcond=None)\n",
    "    \n",
    "#     # Ensure slope is correctly unpacked\n",
    "#     slope = slope[0]\n",
    "    \n",
    "#     # Calculate the characteristic time (assuming y = a * exp(b * time), then b = slope)\n",
    "#     return -1/slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_decay = lambda p, x: (1 - p[1]) * np.exp(-x/p[0]) + p[1]\n",
    "mapExpPlot = lambda y, x = times: plt.plot(x, y/y.iloc[0])\n",
    "mapPlot = lambda y, x = times: plt.plot(x, y)\n",
    "mapPlotExpDecay = lambda p, x = times: plt.plot(x, exp_decay(p, x - x.iloc[0]))\n",
    "plt.figure()\n",
    "# df['S'].map(mapPlot)\n",
    "df[[\"D\", \"T\"]].map(mapPlot)\n",
    "taus.map(mapPlotExpDecay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_columns_by_room(df):\n",
    "    # Dictionary to hold the grouped column names\n",
    "    grouped_volumes = {}\n",
    "\n",
    "    # Loop over each column in the DataFrame\n",
    "    for row, v in df.iterrows():\n",
    "        room_code = row.split('_')[1]\n",
    "        if room_code == \"0-1\": # dual room\n",
    "            room_code = \"1-1\"\n",
    "        elif room_code == \"2-1\":\n",
    "            room_code = \"2-0\"\n",
    "        # Extract the base name by removing the room number\n",
    "        base_name = re.sub(r'room\\d+_\\d-\\d', f'room_{room_code}', row)\n",
    "        if base_name not in grouped_volumes:\n",
    "            grouped_volumes[base_name] = []\n",
    "        grouped_volumes[base_name].append(row)\n",
    "    \n",
    "    # Sum the rows based on the grouped row names\n",
    "    summed_df = {}\n",
    "    for base_name, rows in grouped_volumes.items():\n",
    "        dfCombined = df.loc[rows].apply(sum) / len(rows)\n",
    "        summed_df[base_name] = {}\n",
    "        for col, s in dfCombined.items():\n",
    "            summed_df[base_name][col] = s\n",
    "\n",
    "    return pd.DataFrame(summed_df).T\n",
    "    \n",
    "\n",
    "df_rooms =  sum_columns_by_room(df)\n",
    "taus_rooms = pd.DataFrame()\n",
    "taus_rooms['D'] = df_rooms['D'].map(lambda y: exponential_fit(y, c = 0))\n",
    "taus_rooms['T'] = df_rooms['T'].map(exponential_fit)\n",
    "\n",
    "plt.figure()\n",
    "df_rooms[['D', 'T']].map(mapPlot)\n",
    "taus_rooms.map(mapPlotExpDecay)\n",
    "\n",
    "    # plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
